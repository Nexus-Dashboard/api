# ğŸ“¦ Guia de ExportaÃ§Ã£o de Databases

## ğŸ¯ Objetivo

Exportar todas as databases do MongoDB (F2F e Telephonic) para formatos tabulares (CSV, JSON, Parquet) e compactar em um arquivo ZIP para download.

---

## ğŸš€ OpÃ§Ãµes de ExportaÃ§Ã£o

### OpÃ§Ã£o 1: Via Script (Mais Completo - Com Parquet)

Execute o script standalone que exporta para **3 formatos**: CSV, JSON e Parquet

```bash
node scripts/export-databases.js
```

**O que acontece:**
1. âœ… Conecta aos bancos F2F, Telephonic e Test
2. âœ… Exporta todas as collections (responses, surveys, questionindexes)
3. âœ… Cria arquivos em **3 formatos**:
   - CSV (para Excel/Google Sheets)
   - JSON (backup completo)
   - Parquet (para Python/R/Spark)
4. âœ… Compacta tudo em um arquivo ZIP
5. âœ… Salva em `exports/mongodb_export_[timestamp].zip`

**Resultado:**
```
exports/
â””â”€â”€ mongodb_export_2024-12-02T14-30-00.zip
    â”œâ”€â”€ README.txt
    â”œâ”€â”€ f2f_responses.csv
    â”œâ”€â”€ f2f_responses.json
    â”œâ”€â”€ f2f_responses.parquet
    â”œâ”€â”€ f2f_surveys.csv
    â”œâ”€â”€ f2f_surveys.json
    â”œâ”€â”€ f2f_questionindexes.csv
    â”œâ”€â”€ f2f_questionindexes.json
    â”œâ”€â”€ telephonic_responses.csv
    â”œâ”€â”€ telephonic_responses.json
    â”œâ”€â”€ telephonic_responses.parquet
    â”œâ”€â”€ telephonic_surveys.csv
    â”œâ”€â”€ telephonic_surveys.json
    â”œâ”€â”€ telephonic_questionindexes.csv
    â”œâ”€â”€ telephonic_questionindexes.json
    â”œâ”€â”€ test_responses.csv
    â”œâ”€â”€ test_responses.json
    â””â”€â”€ test_responses.parquet
```

---

### OpÃ§Ã£o 2: Via API (Mais RÃ¡pido - CSV e JSON apenas)

FaÃ§a download direto via navegador ou curl

#### Exportar apenas CSV (Recomendado):
```
GET http://localhost:4000/api/migration/export-databases?format=csv
```

#### Exportar apenas JSON:
```
GET http://localhost:4000/api/migration/export-databases?format=json
```

#### Exportar CSV + JSON:
```
GET http://localhost:4000/api/migration/export-databases?format=all
```

**No navegador:**
- Abra: `http://localhost:4000/api/migration/export-databases?format=csv`
- O download do ZIP inicia automaticamente

---

## ğŸ“Š Formatos de SaÃ­da

### 1. CSV (Comma-Separated Values)

**Ideal para:** Excel, Google Sheets, anÃ¡lise visual

**Exemplo:**
```csv
_id,surveyId,entrevistadoId,rodada,year,P1,P2,P3,...
6687c958acdf3...,6887c959...,180269688,1,2023,Sim,NÃ£o,Talvez,...
```

**Como usar:**
1. Extraia o ZIP
2. Abra o arquivo `.csv` com Excel
3. Todas as respostas estÃ£o em colunas separadas

**CaracterÃ­sticas:**
- âœ… Responses estÃ£o "achatados" (flatten)
- âœ… Cada pergunta (P1, P2, etc.) Ã© uma coluna
- âœ… FÃ¡cil de filtrar e analisar

---

### 2. JSON (JavaScript Object Notation)

**Ideal para:** Backup, programaÃ§Ã£o, re-importaÃ§Ã£o

**Exemplo:**
```json
[
  {
    "_id": "6687c958acdf31acf12bdd05",
    "surveyId": "6887c959acdf3...",
    "entrevistadoId": "180269688",
    "answers": [
      { "k": "P1", "v": "Sim" },
      { "k": "P2", "v": "NÃ£o" }
    ],
    "rodada": 1,
    "year": 2023
  }
]
```

**Como usar:**
```javascript
const data = require('./f2f_responses.json')
console.log(data.length) // Total de responses
```

**CaracterÃ­sticas:**
- âœ… MantÃ©m estrutura original do MongoDB
- âœ… Inclui arrays aninhados (answers)
- âœ… Perfeito para backup completo

---

### 3. Parquet (Apenas no Script)

**Ideal para:** Python, R, Apache Spark, anÃ¡lise de Big Data

**Exemplo (Python/Pandas):**
```python
import pandas as pd

# Ler arquivo parquet
df = pd.read_parquet('f2f_responses.parquet')

# Analisar dados
print(df.head())
print(df.shape)
print(df.columns)

# Filtrar
responses_2023 = df[df['year'] == 2023]
```

**CaracterÃ­sticas:**
- âœ… Formato colunar otimizado
- âœ… CompressÃ£o eficiente
- âœ… Leitura muito rÃ¡pida
- âœ… Ideal para grandes volumes

---

## ğŸ“ Estrutura dos Dados Exportados

### Collections Exportadas:

#### 1. **responses** (Respostas dos Entrevistados)
- **Campos fixos:**
  - `_id`: ID Ãºnico da resposta
  - `surveyId`: ID da pesquisa
  - `entrevistadoId`: ID do entrevistado
  - `rodada`: NÃºmero da rodada
  - `year`: Ano da pesquisa
  - `createdAt`: Data de criaÃ§Ã£o
  - `updatedAt`: Data de atualizaÃ§Ã£o

- **Campos dinÃ¢micos:** (CSV e Parquet)
  - `P1`, `P2`, `P3`, ... : Respostas das perguntas

#### 2. **surveys** (InformaÃ§Ãµes das Pesquisas)
- `_id`: ID da pesquisa
- `name`: Nome da pesquisa
- `year`: Ano
- `month`: MÃªs/Rodada

#### 3. **questionindexes** (Ãndice de Perguntas)
- `variable`: CÃ³digo da pergunta (P1, P2, etc.)
- `questionText`: Texto da pergunta
- `surveyNumber`: NÃºmero da pesquisa
- `possibleAnswers`: Respostas possÃ­veis

---

## ğŸ’¾ Tamanho Estimado dos Arquivos

| Database | Collection | Documentos | CSV | JSON | Parquet |
|----------|-----------|-----------|-----|------|---------|
| F2F | responses | ~53.000 | ~50MB | ~30MB | ~10MB |
| F2F | surveys | ~100 | 10KB | 20KB | - |
| F2F | questionindexes | ~1.500 | 500KB | 1MB | - |
| Telephonic | responses | ~5.000 | ~5MB | ~3MB | ~1MB |
| Telephonic | surveys | ~50 | 5KB | 10KB | - |
| Telephonic | questionindexes | ~1.000 | 300KB | 500KB | - |

**Total ZIP (compactado):** ~20-30MB

---

## ğŸ”„ Processo de "Flatten" (Achatamento)

### Antes (MongoDB/JSON):
```json
{
  "entrevistadoId": "12345",
  "answers": [
    { "k": "P1", "v": "Sim" },
    { "k": "P2", "v": "25" },
    { "k": "P3", "v": "SÃ£o Paulo" }
  ]
}
```

### Depois (CSV/Parquet):
```csv
entrevistadoId,P1,P2,P3
12345,Sim,25,SÃ£o Paulo
```

---

## ğŸ“– Exemplos de Uso

### Excel / Google Sheets (CSV)

1. Extraia o ZIP
2. Abra `f2f_responses.csv`
3. Use filtros para analisar:
   - Filtrar por ano
   - Filtrar por rodada
   - Agrupar respostas

### Python (Pandas)

```python
import pandas as pd

# CSV
df = pd.read_csv('f2f_responses.csv')

# Parquet (mais rÃ¡pido)
df = pd.read_parquet('f2f_responses.parquet')

# AnÃ¡lise
print(df.groupby('year')['entrevistadoId'].count())
print(df['P1'].value_counts())
```

### R (tidyverse)

```r
library(tidyverse)

# CSV
df <- read_csv('f2f_responses.csv')

# AnÃ¡lise
df %>%
  group_by(year) %>%
  summarise(total = n())
```

### JavaScript/Node.js (JSON)

```javascript
const data = require('./f2f_responses.json')

// Total de respostas
console.log(`Total: ${data.length}`)

// Filtrar por ano
const respostas2023 = data.filter(r => r.year === 2023)

// Contar por rodada
const porRodada = data.reduce((acc, r) => {
  acc[r.rodada] = (acc[r.rodada] || 0) + 1
  return acc
}, {})
```

---

## âš ï¸ Notas Importantes

1. **MemÃ³ria:** A exportaÃ§Ã£o carrega todos os dados na memÃ³ria
   - Se tiver problemas, exporte um banco por vez
   - Use o script que processa em lotes

2. **Formato CSV:**
   - Arrays (answers) sÃ£o "achatados" em colunas
   - Cada pergunta vira uma coluna (P1, P2, etc.)

3. **Formato JSON:**
   - MantÃ©m estrutura original
   - Arrays ficam aninhados
   - Ideal para backup

4. **Formato Parquet:**
   - Apenas para responses (muito grande)
   - Requer bibliotecas especÃ­ficas (pandas, arrow)
   - Muito mais eficiente que CSV

---

## ğŸš¨ Troubleshooting

### Erro: "Out of memory"
**SoluÃ§Ã£o:** Use o script ao invÃ©s da API, ele processa em lotes

### Arquivo ZIP muito grande
**SoluÃ§Ã£o:** Exporte apenas CSV: `?format=csv`

### Excel nÃ£o abre CSV corretamente
**SoluÃ§Ã£o:**
1. Abra Excel
2. VÃ¡ em Dados â†’ De Texto/CSV
3. Selecione o arquivo
4. Escolha delimitador: vÃ­rgula

---

## ğŸ’¡ Dicas

1. **Para anÃ¡lise rÃ¡pida:** Use CSV
2. **Para backup:** Use JSON
3. **Para Big Data:** Use Parquet
4. **Para tudo:** Use `format=all`

---

## ğŸ“ Resumo de Comandos

```bash
# Script completo (CSV + JSON + Parquet)
node scripts/export-databases.js

# API - Apenas CSV
curl "http://localhost:4000/api/migration/export-databases?format=csv" -O

# API - CSV + JSON
curl "http://localhost:4000/api/migration/export-databases?format=all" -O
```

---

**Ãšltima atualizaÃ§Ã£o:** Dezembro 2024
